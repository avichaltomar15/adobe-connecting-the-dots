# Adobe India Hackathon 2025 â€“ Connecting the Dots ğŸš€

Welcome to my submission for the Adobe India Hackathon 2025. This repository contains solutions for both **Round 1A (PDF Structure Extraction)** and **Round 1B (Persona-Based Multi-PDF Analysis)**.

---

## ğŸ“ Repository Structure

```
Adobe-India-Hackathon25-main/
â”‚
â”œâ”€â”€ analyze_collection.py         # Main script for Challenge 1B
â”œâ”€â”€ process_pdfs.py               # Main script for Challenge 1A
â”‚
â”œâ”€â”€ sample_dataset/               # Shared resources (if any)
â”‚
â”œâ”€â”€ Challenge_1a/                 # Round 1A Folder
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ process_pdfs.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ sample_dataset/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ Challenge_1b/                 # Round 1B Folder
â”‚   â”œâ”€â”€ Collection 1/
â”‚   â”‚   â”œâ”€â”€ PDFs/
â”‚   â”‚   â”œâ”€â”€ challenge1b_input.json
â”‚   â”‚   â””â”€â”€ challenge1b_output.json
â”‚   â”œâ”€â”€ Collection 2/
â”‚   â”œâ”€â”€ Collection 3/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md (this file)
```

---

### âœ… Challenge 1A â€“ PDF Structure Extraction (Dockerized)

#### ğŸ“Œ Description  
This module extracts structured section-wise content (headings, subheadings, paragraphs) from both text-based and scanned PDFs using a combination of PyMuPDF and OCR (Tesseract). The extracted content is saved in a structured JSON format for downstream tasks.

#### â–¶ï¸ How to Run (Using Docker)

1. Navigate to the Challenge 1A directory:
   cd Challenge_1a

2. Build the Docker image:
   docker build -t adobe-challenge-1a .

3. Run the Docker container:
   docker run --rm -v "$(pwd)/sample_dataset:/app/sample_dataset" adobe-challenge-1a

   - --rm: Automatically removes the container after execution.
   - -v "$(pwd)/sample_dataset:/app/sample_dataset": Mounts the local sample_dataset folder into the container.
   - Output JSON files will be written to the same sample_dataset/ directory.

#### ğŸ“‚ Output

For each PDF in the sample_dataset/ folder, a corresponding structured JSON file will be generated in the same directory. These JSON files contain section-wise extracted content including headings, subheadings, and associated text blocks.

---

## âœ… Challenge 1B â€“ Persona-Based PDF Collection Analysis

### ğŸ“Œ Description

Given a **persona and task**, this module processes multiple PDFs across three collections and extracts the most relevant sections, ranks them, and summarizes them.

### â–¶ï¸ How to Run

1. **Navigate to the main repo folder**:
```bash
cd Adobe-India-Hackathon25-main
```

2. **Install dependencies**:
```bash
pip install -r Challenge_1a/requirements.txt
pip install sentence-transformers transformers
```

3. **Run the script**:
```bash
python analyze_collection.py
```

This script will:
- Process each `Collection {1,2,3}` under `Challenge_1b/`
- Read from `challenge1b_input.json`
- Generate `challenge1b_output.json` with relevant sections and summaries

---


---
## ğŸ›  Tech Stack

- Python 3.8+
- PyMuPDF (fitz)
- pytesseract & OpenCV (for OCR)
- Transformers & SentenceTransformers (for relevance & embeddings)
- Docker support (Challenge 1A)
- 
---

## ğŸ™ Acknowledgement

Thanks to Adobe India for this incredible opportunity to explore real-world NLP and PDF extraction use cases!

---

